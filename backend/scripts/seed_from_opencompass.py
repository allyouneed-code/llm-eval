import os
import sys
import glob
import json
import ast
import re
import logging
from sqlmodel import Session, select

# 1. é™éŸ³è®¾ç½®
logging.basicConfig()
logging.getLogger('sqlalchemy.engine').setLevel(logging.ERROR)

# 2. ç¯å¢ƒè®¾ç½®
current_dir = os.path.dirname(os.path.abspath(__file__))
backend_dir = os.path.dirname(current_dir)
sys.path.append(backend_dir)

from app.core.database import engine
from app.models.dataset import DatasetMeta, DatasetConfig
# å¼•å…¥ Task å’Œ Result é˜²æ­¢å…³ç³»æŠ¥é”™
from app.models.task import EvaluationTask
from app.models.result import EvaluationResult

# 3. åŠ è½½å®˜æ–¹æ˜ å°„è¡¨
CAPABILITY_MAP_FILE = os.path.join(current_dir, "dataset_capabilities.json")
CAPABILITY_MAP = {}
if os.path.exists(CAPABILITY_MAP_FILE):
    try:
        with open(CAPABILITY_MAP_FILE, "r", encoding="utf-8") as f:
            raw_map = json.load(f)
            # è½¬å°å†™é”®ï¼Œæ–¹ä¾¿åŒ¹é…
            CAPABILITY_MAP = {k.lower(): v for k, v in raw_map.items()}
    except: pass

# 4. Evaluator æ˜ å°„è¡¨ (ä¿æŒä¸å˜)
EVALUATOR_MAPPING = {
    "AccEvaluator": "Accuracy",
    "AccwithDetailsEvaluator": "Accuracy",
    "Accuracy": "Accuracy",
    "EMEvaluator": "Exact Match",
    "ExactMatchEvaluator": "Exact Match",
    "HumanEvalEvaluator": "Pass@k",
    "MBPPEvaluator": "Pass@k",
    "BigCodeBenchEvaluator": "Pass@k",
    "HumanevalPlusEvaluator": "Pass@k",
    "HumanevalXEvaluator": "Pass@k",
    "MBPPPassKEvaluator": "Pass@k",
    "DS1000Evaluator": "Pass@k",
    "LCBCodeGenerationEvaluator": "Pass@k",
    "CodeCompassEvaluator": "Pass@k",
    "SciCodeEvaluator": "Pass@k",
    "MATHEvaluator": "Accuracy",
    "Gsm8kEvaluator": "Accuracy",
    "MathVerifyEvaluator": "Accuracy",
    "LiveMathBenchEvaluator": "Accuracy",
    "GaoKaoMATHEvaluator": "Accuracy",
    "OmniMathEvaluator": "Accuracy",
    "SuperGPQAEvaluator": "Accuracy",
    "MMLUEvaluator": "Accuracy",
    "MMLUProBaseEvaluator": "Accuracy",
    "AGIEvalEvaluator": "Accuracy",
    "CEvalEvaluator": "Accuracy",
    "CMPhysBenchEvaluator": "Accuracy",
    "GPQAEvaluator": "Accuracy",
    "BBHEvaluator": "Exact Match",
    "TriviaQAEvaluator": "Exact Match",
    "DropEvaluator": "F1 Score",
    "TruthfulQAEvaluator": "Truthfulness",
    "BleuEvaluator": "BLEU",
    "RougeEvaluator": "ROUGE",
    "JiebaRougeEvaluator": "ROUGE",
    "MeteorEvaluator": "METEOR",
    "LVEvalOPTRougeEvaluator": "ROUGE",
    "NeedleBenchOriginEvaluator": "Recall",
    "NeedleBenchMultiEvaluator": "Recall",
    "NeedleBenchParallelEvaluator": "Recall",
    "RulerNiahEvaluator": "Recall",
    "LongBenchF1Evaluator": "F1 Score",
    "LongBenchRougeEvaluator": "ROUGE",
    "LVEvalF1Evaluator": "F1 Score",
    "BabiLongEvaluator": "Accuracy",
    "GenericLLMEvaluator": "LLM Score",
    "LMEvaluator": "Perplexity", 
    "JudgeEvaluator": "LLM Score",
    "ArenaHardEvaluator": "Win Rate",
    "ToxicEvaluator": "Toxicity",
    "CrowspairsEvaluator": "Accuracy",
    "CircularEvaluator": "Consistency",
    "AttackSuccessRate": "ASR"
}

VERSION_PATTERN = re.compile(r'_[0-9a-f]{6}\.py$')
REGEX_EVALUATOR = re.compile(r"\b([a-zA-Z0-9_]+Evaluator)\b")

# ==========================================
# ğŸ§  æå– Metric
# ==========================================
def extract_metric_from_file(file_path):
    content = ""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
    except: return None
    matches = REGEX_EVALUATOR.findall(content)
    for eval_cls in reversed(matches):
        if eval_cls in EVALUATOR_MAPPING: return EVALUATOR_MAPPING[eval_cls]
        if "Acc" in eval_cls: return "Accuracy"
        if "Bleu" in eval_cls: return "BLEU"
        if "Rouge" in eval_cls: return "ROUGE"
        if "PassK" in eval_cls: return "Pass@k"
        if "ExactMatch" in eval_cls: return "Exact Match"
    return None

def infer_metric_by_filename(filename):
    name = filename.lower()
    if 'code' in name or 'mbpp' in name or 'humaneval' in name: return "Pass@k"
    if 'math' in name or 'gsm8k' in name: return "Accuracy"
    if 'translation' in name or 'wmt' in name: return "BLEU"
    if 'summarization' in name: return "ROUGE"
    return "Accuracy"

# ==========================================
# ğŸ·ï¸ Mode æ¨æ–­
# ==========================================
def infer_mode_strict(filename):
    name = filename.replace(".py", "").lower()
    if "_gen" in name: return "gen"
    if "_ppl" in name: return "ppl"
    if "_mixed" in name: return "mixed"
    return None

# ==========================================
# ğŸ“‚ æ™ºèƒ½åˆ†ç±»æ¨æ–­ (V8 ä¸¥æ ¼ç‰ˆ)
# ==========================================

def infer_category_heuristics(name):
    """å…³é”®è¯å…œåº•é€»è¾‘ (å¢å¼ºç‰ˆ)"""
    n = name.lower()
    # Math
    if any(x in n for x in ['math', 'gsm8k', 'arithmetic', 'theorem', 'algebra', 'calculus']): return "Math"
    # Code
    if any(x in n for x in ['code', 'mbpp', 'humaneval', 'python', 'java', 'sql']): return "Code"
    # Examination / Knowledge
    if any(x in n for x in ['mmlu', 'ceval', 'agieval', 'exam', 'bench', 'choice']): return "Knowledge"
    # NLP / Translation
    if any(x in n for x in ['translation', 'wmt', 'bleu', 'flores']): return "Translation"
    # Dialogue / Chat
    if any(x in n for x in ['chat', 'dialog', 'conversation']): return "Dialogue"
    # Safety
    if any(x in n for x in ['safety', 'toxic', 'bias', 'jailbreak']): return "Safety"
    # Reasoning
    if any(x in n for x in ['reason', 'logic', 'nli', 'qa', 'reading', 'arc', 'hellaswag']): return "Reasoning"
    # Long Context (ğŸŒŸ æ–°å¢ï¼Œè§£å†³ lveval é—®é¢˜)
    if any(x in n for x in ['long', 'context', 'needle', 'lveval', 'lv-eval', 'book']): return "Long Context"
    # Vision / Multimodal (ä»¥é˜²ä¸‡ä¸€)
    if any(x in n for x in ['vision', 'image', 'video', 'mmbench']): return "Multimodal"
    
    return None

def resolve_meta_and_category(file_path, oc_root):
    """
    V8 ç­–ç•¥ï¼šéç™½åå•å³ Other
    """
    abs_datasets_dir = os.path.join(oc_root, "configs", "datasets")
    if not file_path.startswith(abs_datasets_dir):
        return os.path.basename(os.path.dirname(file_path)), "Other"
        
    rel_path = os.path.relpath(file_path, abs_datasets_dir)
    parts = rel_path.replace("\\", "/").split("/")
    
    # 1. ç¡®å®š Meta Name (ä¾ç„¶æ˜¯çˆ¶æ–‡ä»¶å¤¹åï¼Œè¿™åœ¨ adv_glue_mnli é‡Œæ˜¯å¯¹çš„)
    meta_name = parts[-2] if len(parts) >= 2 else parts[0]
    
    # 2. ç¡®å®š Category
    category = "Other" # é»˜è®¤å€¼
    
    # ç­–ç•¥ A: æŸ¥å®˜æ–¹æ˜ å°„è¡¨ (ç²¾ç¡®åŒ¹é… Meta Name)
    if meta_name.lower() in CAPABILITY_MAP:
        category = CAPABILITY_MAP[meta_name.lower()]
    
    # ç­–ç•¥ B: æŸ¥å®˜æ–¹æ˜ å°„è¡¨ (æ¨¡ç³ŠåŒ¹é…)
    if category == "Other":
        for k, v in CAPABILITY_MAP.items():
            if k in meta_name.lower():
                category = v
                break
    
    # ç­–ç•¥ C: å…³é”®è¯å…œåº• (Heuristics)
    if category == "Other":
        h_cat = infer_category_heuristics(meta_name)
        if h_cat:
            category = h_cat
            
    # âŒ ç§»é™¤æ—§ç­–ç•¥ D: "category = parts[0]"
    # å¦‚æœä¸Šé¢éƒ½æ²¡åŒ¹é…åˆ°ï¼Œé‚£å°±æ˜¯ "Other"ï¼Œç»ä¸ä½¿ç”¨æ–‡ä»¶å¤¹åä½œä¸ºåˆ†ç±»ã€‚

    return meta_name, category

# ==========================================
# ğŸš€ ä¸»æµç¨‹
# ==========================================
def process_and_save(session: Session, oc_root: str):
    target_dir = os.path.join(oc_root, "configs", "datasets")
    if not os.path.exists(target_dir):
        if os.path.exists(oc_root) and "datasets" in oc_root:
            target_dir = oc_root
            oc_root = os.path.dirname(os.path.dirname(target_dir))
        else:
            print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ° configs/datasets è·¯å¾„ -> {target_dir}")
            return

    print(f"ğŸš€ [V8-çº¯å‡€åˆ†ç±»ç‰ˆ] å¼€å§‹æ‰«æ: {target_dir}")
    print(f"   â„¹ï¸  ç­–ç•¥: æ˜ å°„è¡¨ > å…³é”®è¯ > Other (æ‹’ç»ä½¿ç”¨æ–‡ä»¶å¤¹åä½œä¸ºåˆ†ç±»)")
    
    py_files = glob.glob(os.path.join(target_dir, "**/*.py"), recursive=True)
    print(f"ğŸ“„ ç‰©ç†æ–‡ä»¶æ€»æ•°: {len(py_files)}")
    
    success_count = 0
    skipped_count = 0
    
    for i, file_path in enumerate(py_files):
        if i > 0 and i % 500 == 0: print(f"   ...è¿›åº¦ {i}/{len(py_files)}")
        
        filename = os.path.basename(file_path)
        if filename == "__init__.py": continue
        if VERSION_PATTERN.search(filename): continue
        if filename.endswith("_settings.py") or filename.endswith("_base.py") or filename.endswith("_common.py"):
            skipped_count += 1
            continue

        try:
            # 1. Strict Mode
            mode = infer_mode_strict(filename)
            if not mode:
                skipped_count += 1
                continue

            # 2. Resolve Meta & Category (V8 Logic)
            meta_name, category = resolve_meta_and_category(file_path, oc_root)
            
            # 3. Metric
            metric = extract_metric_from_file(file_path)
            if not metric:
                metric = infer_metric_by_filename(filename)
            
            # 4. DB Operations
            # Meta
            meta = session.exec(select(DatasetMeta).where(DatasetMeta.name == meta_name)).first()
            if not meta:
                meta = DatasetMeta(name=meta_name, category=category, description="Official Dataset")
                session.add(meta)
                session.flush()
            else:
                # ğŸŒŸ å¼ºåˆ¶ä¿®æ­£ Category: å¦‚æœä¹‹å‰å½•å…¥çš„æ˜¯æ–‡ä»¶å¤¹å(é”™çš„)æˆ–è€…Otherï¼Œå°è¯•æ›´æ–°ä¸ºæ›´å‡†ç¡®çš„
                # ç°åœ¨çš„é€»è¾‘æ˜¯ï¼šé™¤éåŒ¹é…åˆ°æ˜ç¡®çš„ map æˆ– heuristicsï¼Œå¦åˆ™å°±æ˜¯ Other
                # æ‰€ä»¥æˆ‘ä»¬ç›¸ä¿¡è¿™ä¸€æ¬¡çš„åˆ¤æ–­
                if meta.category != category:
                     meta.category = category
                     session.add(meta)
                     session.flush()

            # Config
            config_name = filename.replace('.py', '')
            try:
                rel_path = os.path.relpath(file_path, oc_root).replace("\\", "/")
            except:
                rel_path = f"configs/datasets/{meta_name}/{filename}"
            official_path = f"official://{rel_path}"

            existing = session.exec(select(DatasetConfig).where(DatasetConfig.config_name == config_name, DatasetConfig.meta_id == meta.id)).first()
            
            if existing:
                if existing.display_metric != metric or existing.mode != mode or existing.file_path != official_path:
                    existing.display_metric = metric
                    existing.mode = mode
                    existing.file_path = official_path
                    session.add(existing)
                    session.commit()
                continue
            
            db_config = DatasetConfig(
                meta_id=meta.id,
                config_name=config_name,
                mode=mode,
                file_path=official_path,
                display_metric=metric,
                reader_cfg="{}", infer_cfg="{}", metric_config="{}"
            )
            session.add(db_config)
            session.commit()
            success_count += 1
            
        except Exception:
            session.rollback()
            continue

    print(f"\nğŸ‰ V8 å½•å…¥å®Œæˆï¼")
    print(f"   âœ… æˆåŠŸå½•å…¥: {success_count}")
    print(f"   ğŸ§¹ è¿‡æ»¤å™ªéŸ³: {skipped_count}")

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python scripts/seed_via_ast_v8.py <path>")
        sys.exit(1)
    
    from sqlmodel import SQLModel
    SQLModel.metadata.create_all(engine)
    
    with Session(engine) as session:
        process_and_save(session, sys.argv[1])