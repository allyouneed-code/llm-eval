import os
import sys
import glob
import json
import ast
import re
import logging
from sqlmodel import Session, select

# 1. é™éŸ³è®¾ç½®
logging.basicConfig()
logging.getLogger('sqlalchemy.engine').setLevel(logging.ERROR)

# 2. ç¯å¢ƒè®¾ç½®
current_dir = os.path.dirname(os.path.abspath(__file__))
backend_dir = os.path.dirname(current_dir)
sys.path.append(backend_dir)

from app.core.database import engine
from app.models.dataset import DatasetMeta, DatasetConfig
# å¼•å…¥ Task å’Œ Result é˜²æ­¢å…³ç³»æŠ¥é”™
from app.models.task import EvaluationTask
from app.models.result import EvaluationResult

# 3. åŠ è½½å®˜æ–¹æ˜ å°„è¡¨
CAPABILITY_MAP_FILE = os.path.join(current_dir, "dataset_capabilities.json")
CAPABILITY_MAP = {}
if os.path.exists(CAPABILITY_MAP_FILE):
    try:
        with open(CAPABILITY_MAP_FILE, "r", encoding="utf-8") as f:
            raw_map = json.load(f)
            # è½¬å°å†™é”®ï¼Œæ–¹ä¾¿åŒ¹é…
            CAPABILITY_MAP = {k.lower(): v for k, v in raw_map.items()}
    except: pass

# 4. Evaluator æ˜ å°„è¡¨ (ä¿æŒä¸å˜)
EVALUATOR_MAPPING = {
    "AccEvaluator": "Accuracy",
    "AccwithDetailsEvaluator": "Accuracy",
    "Accuracy": "Accuracy",
    "EMEvaluator": "Exact Match",
    "ExactMatchEvaluator": "Exact Match",
    "HumanEvalEvaluator": "Pass@k",
    "MBPPEvaluator": "Pass@k",
    "BigCodeBenchEvaluator": "Pass@k",
    "HumanevalPlusEvaluator": "Pass@k",
    "HumanevalXEvaluator": "Pass@k",
    "MBPPPassKEvaluator": "Pass@k",
    "DS1000Evaluator": "Pass@k",
    "LCBCodeGenerationEvaluator": "Pass@k",
    "CodeCompassEvaluator": "Pass@k",
    "SciCodeEvaluator": "Pass@k",
    "MATHEvaluator": "Accuracy",
    "Gsm8kEvaluator": "Accuracy",
    "MathVerifyEvaluator": "Accuracy",
    "LiveMathBenchEvaluator": "Accuracy",
    "GaoKaoMATHEvaluator": "Accuracy",
    "OmniMathEvaluator": "Accuracy",
    "SuperGPQAEvaluator": "Accuracy",
    "MMLUEvaluator": "Accuracy",
    "MMLUProBaseEvaluator": "Accuracy",
    "AGIEvalEvaluator": "Accuracy",
    "CEvalEvaluator": "Accuracy",
    "CMPhysBenchEvaluator": "Accuracy",
    "GPQAEvaluator": "Accuracy",
    "BBHEvaluator": "Exact Match",
    "TriviaQAEvaluator": "Exact Match",
    "DropEvaluator": "F1 Score",
    "TruthfulQAEvaluator": "Truthfulness",
    "BleuEvaluator": "BLEU",
    "RougeEvaluator": "ROUGE",
    "JiebaRougeEvaluator": "ROUGE",
    "MeteorEvaluator": "METEOR",
    "LVEvalOPTRougeEvaluator": "ROUGE",
    "NeedleBenchOriginEvaluator": "Recall",
    "NeedleBenchMultiEvaluator": "Recall",
    "NeedleBenchParallelEvaluator": "Recall",
    "RulerNiahEvaluator": "Recall",
    "LongBenchF1Evaluator": "F1 Score",
    "LongBenchRougeEvaluator": "ROUGE",
    "LVEvalF1Evaluator": "F1 Score",
    "BabiLongEvaluator": "Accuracy",
    "GenericLLMEvaluator": "LLM Score",
    "LMEvaluator": "Perplexity", 
    "JudgeEvaluator": "LLM Score",
    "ArenaHardEvaluator": "Win Rate",
    "ToxicEvaluator": "Toxicity",
    "CrowspairsEvaluator": "Accuracy",
    "CircularEvaluator": "Consistency",
    "AttackSuccessRate": "ASR"
}

VERSION_PATTERN = re.compile(r'_[0-9a-f]{6}\.py$')
REGEX_EVALUATOR = re.compile(r"\b([a-zA-Z0-9_]+Evaluator)\b")

# ==========================================
# ğŸ§  æå– Metric (åŸæœ‰é€»è¾‘)
# ==========================================
def extract_metric_from_file(file_path):
    content = ""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
    except: return None
    matches = REGEX_EVALUATOR.findall(content)
    for eval_cls in reversed(matches):
        if eval_cls in EVALUATOR_MAPPING: return EVALUATOR_MAPPING[eval_cls]
        if "Acc" in eval_cls: return "Accuracy"
        if "Bleu" in eval_cls: return "BLEU"
        if "Rouge" in eval_cls: return "ROUGE"
        if "PassK" in eval_cls: return "Pass@k"
        if "ExactMatch" in eval_cls: return "Exact Match"
    return None

def infer_metric_by_filename(filename):
    name = filename.lower()
    if 'code' in name or 'mbpp' in name or 'humaneval' in name: return "Pass@k"
    if 'math' in name or 'gsm8k' in name: return "Accuracy"
    if 'translation' in name or 'wmt' in name: return "BLEU"
    if 'summarization' in name: return "ROUGE"
    return "Accuracy"

# ==========================================
# ğŸ·ï¸ Mode æ¨æ–­ (åŸæœ‰é€»è¾‘)
# ==========================================
def infer_mode_strict(filename):
    name = filename.replace(".py", "").lower()
    if "_gen" in name: return "gen"
    if "_ppl" in name: return "ppl"
    if "_mixed" in name: return "mixed"
    return None

# ==========================================
# ğŸ“‚ æ™ºèƒ½åˆ†ç±»æ¨æ–­ (V8 ä¸¥æ ¼ç‰ˆ) (åŸæœ‰é€»è¾‘)
# ==========================================
def infer_category_heuristics(name):
    """å…³é”®è¯å…œåº•é€»è¾‘ (å¢å¼ºç‰ˆ)"""
    n = name.lower()
    # Math
    if any(x in n for x in ['math', 'gsm8k', 'arithmetic', 'theorem', 'algebra', 'calculus']): return "Math"
    # Code
    if any(x in n for x in ['code', 'mbpp', 'humaneval', 'python', 'java', 'sql']): return "Code"
    # Examination / Knowledge
    if any(x in n for x in ['mmlu', 'ceval', 'agieval', 'exam', 'bench', 'choice']): return "Knowledge"
    # NLP / Translation
    if any(x in n for x in ['translation', 'wmt', 'bleu', 'flores']): return "Translation"
    # Dialogue / Chat
    if any(x in n for x in ['chat', 'dialog', 'conversation']): return "Dialogue"
    # Safety
    if any(x in n for x in ['safety', 'toxic', 'bias', 'jailbreak']): return "Safety"
    # Reasoning
    if any(x in n for x in ['reason', 'logic', 'nli', 'qa', 'reading', 'arc', 'hellaswag']): return "Reasoning"
    # Long Context (ğŸŒŸ æ–°å¢ï¼Œè§£å†³ lveval é—®é¢˜)
    if any(x in n for x in ['long', 'context', 'needle', 'lveval', 'lv-eval', 'book']): return "Long Context"
    # Vision / Multimodal (ä»¥é˜²ä¸‡ä¸€)
    if any(x in n for x in ['vision', 'image', 'video', 'mmbench']): return "Multimodal"
    
    return None

def resolve_meta_and_category(file_path, oc_root):
    """
    V8 ç­–ç•¥ï¼šéç™½åå•å³ Other
    """
    abs_datasets_dir = os.path.join(oc_root, "configs", "datasets")
    if not file_path.startswith(abs_datasets_dir):
        return os.path.basename(os.path.dirname(file_path)), "Other"
        
    rel_path = os.path.relpath(file_path, abs_datasets_dir)
    parts = rel_path.replace("\\", "/").split("/")
    
    # 1. ç¡®å®š Meta Name (ä¾ç„¶æ˜¯çˆ¶æ–‡ä»¶å¤¹åï¼Œè¿™åœ¨ adv_glue_mnli é‡Œæ˜¯å¯¹çš„)
    meta_name = parts[-2] if len(parts) >= 2 else parts[0]
    
    # 2. ç¡®å®š Category
    category = "Other" # é»˜è®¤å€¼
    
    # ç­–ç•¥ A: æŸ¥å®˜æ–¹æ˜ å°„è¡¨ (ç²¾ç¡®åŒ¹é… Meta Name)
    if meta_name.lower() in CAPABILITY_MAP:
        category = CAPABILITY_MAP[meta_name.lower()]
    
    # ç­–ç•¥ B: æŸ¥å®˜æ–¹æ˜ å°„è¡¨ (æ¨¡ç³ŠåŒ¹é…)
    if category == "Other":
        for k, v in CAPABILITY_MAP.items():
            if k in meta_name.lower():
                category = v
                break
    
    # ç­–ç•¥ C: å…³é”®è¯å…œåº• (Heuristics)
    if category == "Other":
        h_cat = infer_category_heuristics(meta_name)
        if h_cat:
            category = h_cat
            
    return meta_name, category

# ==========================================
# ğŸ†• æ–°å¢ï¼šAST è¾…åŠ©å‡½æ•°ï¼Œç”¨äºæå–åå¤„ç†é…ç½®
# ==========================================
def ast_to_dict(node):
    """å°† AST dict èŠ‚ç‚¹è½¬æ¢ä¸º Python dict"""
    if isinstance(node, ast.Dict):
        return {ast_to_dict(k): ast_to_dict(v) for k, v in zip(node.keys, node.values)}
    elif isinstance(node, ast.Call) and isinstance(node.func, ast.Name) and node.func.id == 'dict':
        return {k.arg: ast_to_dict(k.value) for k in node.keywords}
    elif isinstance(node, ast.Constant): # Python 3.8+
        return node.value
    elif isinstance(node, ast.Str): # Python < 3.8
        return node.s
    elif isinstance(node, ast.Num): # Python < 3.8
        return node.n
    elif isinstance(node, ast.Name): # å¼•ç”¨äº†å˜é‡ï¼Œè¿™é‡Œç®€åŒ–å¤„ç†è¿”å›å˜é‡åå­—ç¬¦ä¸²
        return node.id 
    return None

def parse_ast_for_extra_fields(file_path):
    """
    ä½¿ç”¨ AST æå– task_type å’Œ post_process_cfg
    """
    evaluator_type = ""
    post_process_cfg = {}
    
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            tree = ast.parse(f.read())
        
        # å¯»æ‰¾ eval_cfg èµ‹å€¼è¯­å¥
        for node in tree.body:
            if isinstance(node, ast.Assign):
                for target in node.targets:
                    if isinstance(target, ast.Name) and target.id == 'eval_cfg':
                        # æ‰¾åˆ°äº† eval_cfg = ...
                        value_node = node.value
                        
                        # è§£æ evaluator
                        # å‡è®¾ç»“æ„æ˜¯ dict(evaluator=dict(type=...), pred_postprocessor=dict(...))
                        if isinstance(value_node, ast.Call) and value_node.keywords:
                            for kw in value_node.keywords:
                                # æå– evaluator.type
                                if kw.arg == 'evaluator':
                                    ev_dict = ast_to_dict(kw.value)
                                    if ev_dict and 'type' in ev_dict:
                                        evaluator_type = str(ev_dict['type'])
                                
                                # æå– pred_postprocessor
                                if kw.arg == 'pred_postprocessor':
                                    pp_dict = ast_to_dict(kw.value)
                                    if pp_dict:
                                        post_process_cfg = pp_dict
                        break
    except Exception as e:
        # AST è§£æå¤±è´¥ä¸åº”é˜»å¡ä¸»æµç¨‹ï¼Œä»…é™é»˜å¤±è´¥
        pass
        
    return evaluator_type, post_process_cfg

def infer_task_type(evaluator_type, post_process_cfg):
    """
    æ ¹æ®æå–åˆ°çš„ä¿¡æ¯æ¨æ–­ä»»åŠ¡ç±»å‹
    """
    pp_type = str(post_process_cfg.get('type', '')).lower()
    ev_type = evaluator_type.lower()
    
    # 1. å¦‚æœæœ‰æ˜ç¡®çš„æå–é€‰é¡¹åå¤„ç† -> é€‰æ‹©é¢˜
    if 'option' in pp_type or 'capital' in pp_type:
        return 'multiple_choice'
    
    # 2. å¦‚æœ Evaluator æ˜¯ Accuracy ç±»å‹ -> å€¾å‘äºé€‰æ‹©é¢˜ (è™½ç„¶æ•°å­¦é¢˜ä¹Ÿæ˜¯ Acc)
    if 'acc' in ev_type:
        return 'multiple_choice' 
        
    # 3. å¡«ç©ºé¢˜
    if 'em' in ev_type or 'exact' in ev_type:
        return 'cloze'
        
    # 4. é»˜è®¤é—®ç­”/ç”Ÿæˆ
    return 'qa'

# ==========================================
# ğŸš€ ä¸»æµç¨‹
# ==========================================
def process_and_save(session: Session, oc_root: str):
    target_dir = os.path.join(oc_root, "configs", "datasets")
    if not os.path.exists(target_dir):
        if os.path.exists(oc_root) and "datasets" in oc_root:
            target_dir = oc_root
            oc_root = os.path.dirname(os.path.dirname(target_dir))
        else:
            print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ° configs/datasets è·¯å¾„ -> {target_dir}")
            return

    print(f"ğŸš€ [V8-çº¯å‡€åˆ†ç±»ç‰ˆ] å¼€å§‹æ‰«æ: {target_dir}")
    print(f"   â„¹ï¸  ç­–ç•¥: æ˜ å°„è¡¨ > å…³é”®è¯ > Other (æ‹’ç»ä½¿ç”¨æ–‡ä»¶å¤¹åä½œä¸ºåˆ†ç±»)")
    
    py_files = glob.glob(os.path.join(target_dir, "**/*.py"), recursive=True)
    print(f"ğŸ“„ ç‰©ç†æ–‡ä»¶æ€»æ•°: {len(py_files)}")
    
    success_count = 0
    skipped_count = 0
    
    for i, file_path in enumerate(py_files):
        if i > 0 and i % 500 == 0: print(f"   ...è¿›åº¦ {i}/{len(py_files)}")
        
        filename = os.path.basename(file_path)
        if filename == "__init__.py": continue
        if VERSION_PATTERN.search(filename): continue
        if filename.endswith("_settings.py") or filename.endswith("_base.py") or filename.endswith("_common.py"):
            skipped_count += 1
            continue

        try:
            # 1. Strict Mode (åŸæœ‰é€»è¾‘)
            mode = infer_mode_strict(filename)
            if not mode:
                skipped_count += 1
                continue

            # 2. Resolve Meta & Category (V8 Logic) (åŸæœ‰é€»è¾‘)
            meta_name, category = resolve_meta_and_category(file_path, oc_root)
            
            # 3. Metric (åŸæœ‰é€»è¾‘)
            metric = extract_metric_from_file(file_path)
            if not metric:
                metric = infer_metric_by_filename(filename)
            
            # 4. ğŸ†• Extract Extra Fields (æ–°å¢é€»è¾‘)
            # ä½¿ç”¨ AST æå–åå¤„ç†é…ç½®å’Œè¯„ä¼°å™¨ç±»å‹ï¼Œç”¨äºæ¨æ–­ task_type
            ast_eval_type, ast_pp_cfg = parse_ast_for_extra_fields(file_path)
            task_type = infer_task_type(ast_eval_type, ast_pp_cfg)
            
            # 5. DB Operations
            # Meta
            meta = session.exec(select(DatasetMeta).where(DatasetMeta.name == meta_name)).first()
            if not meta:
                meta = DatasetMeta(name=meta_name, category=category, description="Official Dataset")
                session.add(meta)
                session.flush()
            else:
                if meta.category != category:
                     meta.category = category
                     session.add(meta)
                     session.flush()

            # Config
            config_name = filename.replace('.py', '')
            try:
                rel_path = os.path.relpath(file_path, oc_root).replace("\\", "/")
            except:
                rel_path = f"configs/datasets/{meta_name}/{filename}"
            official_path = f"official://{rel_path}"

            existing = session.exec(select(DatasetConfig).where(DatasetConfig.config_name == config_name, DatasetConfig.meta_id == meta.id)).first()
            
            if existing:
                # æ›´æ–°é€»è¾‘å¢åŠ  task_type å’Œ post_process_cfg
                needs_update = False
                if existing.display_metric != metric: existing.display_metric = metric; needs_update = True
                if existing.mode != mode: existing.mode = mode; needs_update = True
                if existing.file_path != official_path: existing.file_path = official_path; needs_update = True
                # ğŸ†• å¢åŠ å¯¹æ–°å­—æ®µçš„æ›´æ–°
                if existing.task_type != task_type: existing.task_type = task_type; needs_update = True
                new_pp_json = json.dumps(ast_pp_cfg, ensure_ascii=False)
                if existing.post_process_cfg != new_pp_json: existing.post_process_cfg = new_pp_json; needs_update = True
                
                if needs_update:
                    session.add(existing)
                    session.commit()
                continue
            
            db_config = DatasetConfig(
                meta_id=meta.id,
                config_name=config_name,
                mode=mode,
                file_path=official_path,
                display_metric=metric,
                
                # ğŸ†• å¡«å…¥æ–°å­—æ®µ
                task_type=task_type,
                post_process_cfg=json.dumps(ast_pp_cfg, ensure_ascii=False),
                
                reader_cfg="{}", infer_cfg="{}", metric_config="{}"
            )
            session.add(db_config)
            session.commit()
            success_count += 1
            
        except Exception:
            session.rollback()
            continue

    print(f"\nğŸ‰ V8 å½•å…¥å®Œæˆï¼")
    print(f"   âœ… æˆåŠŸå½•å…¥: {success_count}")
    print(f"   ğŸ§¹ è¿‡æ»¤å™ªéŸ³: {skipped_count}")

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python scripts/seed_via_ast_v8.py <path>")
        sys.exit(1)
    
    from sqlmodel import SQLModel
    SQLModel.metadata.create_all(engine)
    
    with Session(engine) as session:
        process_and_save(session, sys.argv[1])