import json
import os
import shutil
from datetime import datetime
from fastapi import HTTPException
from sqlmodel import Session, select
from typing import List, Optional, Dict, Any

from app.models.task import EvaluationTask
from app.models.llm_model import LLMModel
from app.models.dataset import DatasetConfig
from app.models.links import TaskDatasetLink
from app.models.result import EvaluationResult
from app.models.scheme import EvaluationScheme
from app.schemas.task_schema import TaskCreate
# ğŸ†• å¼•å…¥ Runner
from app.services.opencompass_runner import OpenCompassRunner

class TaskService:
    def __init__(self, session: Session):
        self.session = session

    # create_task, delete_task, get_task ç­‰æ–¹æ³•ä¿æŒä¸å˜...
    # (æ­¤å¤„çœç•¥æœªä¿®æ”¹çš„æ–¹æ³•ï¼Œè¯·ä¿ç•™åŸæ–‡ä»¶ä¸­çš„è¿™äº›ä»£ç )
    
    def create_task(self, task_in: TaskCreate) -> EvaluationTask:
        # ... (ä¿æŒåŸæœ‰çš„ create_task é€»è¾‘ä¸å˜) ...
        # è¯·ç¡®ä¿æŠŠåŸæ–‡ä»¶ä¸­çš„ create_task ä»£ç å®Œæ•´ä¿ç•™åœ¨è¿™é‡Œ
        model = self.session.get(LLMModel, task_in.model_id)
        if not model:
            raise HTTPException(status_code=404, detail="æ‰€é€‰æ¨¡å‹ä¸å­˜åœ¨")
        
        target_config_ids = task_in.config_ids or []

        if task_in.scheme_id:
            scheme = self.session.get(EvaluationScheme, task_in.scheme_id)
            if not scheme:
                raise HTTPException(status_code=404, detail="æ‰€é€‰è¯„æµ‹æ–¹æ¡ˆä¸å­˜åœ¨")
            scheme_configs = scheme.configs
            if not scheme_configs:
                raise HTTPException(status_code=400, detail="è¯¥è¯„æµ‹æ–¹æ¡ˆæœªåŒ…å«ä»»ä½•æœ‰æ•ˆçš„æ•°æ®é›†é…ç½®")
            target_config_ids = [c.id for c in scheme_configs]
        
        if not target_config_ids:
            raise HTTPException(status_code=400, detail="æœªé€‰æ‹©ä»»ä½•è¯„æµ‹æ•°æ®é›†")

        statement = select(DatasetConfig).where(DatasetConfig.id.in_(target_config_ids))
        configs = self.session.exec(statement).all()
        
        if len(configs) != len(set(target_config_ids)):
             raise HTTPException(status_code=400, detail="éƒ¨åˆ†è¯„æµ‹é…ç½®ä¸å­˜åœ¨æˆ–IDé‡å¤")
        
        datasets_json = json.dumps([c.id for c in configs])
        
        db_task = EvaluationTask(
            model_id=task_in.model_id,
            datasets_list=datasets_json,
            scheme_id=task_in.scheme_id,
            status="pending",
            progress=0
        )
        self.session.add(db_task)
        self.session.commit()
        self.session.refresh(db_task)
        
        for config in configs:
            snapshot_json = json.dumps(config.model_dump(mode='json'), default=str)
            link = TaskDatasetLink(
                task_id=db_task.id,
                dataset_config_id=config.id,
                config_snapshot=snapshot_json
            )
            self.session.add(link)
        
        self.session.commit()
        return db_task

    def delete_task(self, task_id: int) -> bool:
        task = self.get_task(task_id)
        if not task:
            return False
        results = self.session.exec(select(EvaluationResult).where(EvaluationResult.task_id == task_id)).all()
        for r in results:
            self.session.delete(r)
        links = self.session.exec(select(TaskDatasetLink).where(TaskDatasetLink.task_id == task_id)).all()
        for l in links:
            self.session.delete(l)  
        self.session.delete(task)
        self.session.commit()
        return True

    def get_task(self, task_id: int) -> Optional[EvaluationTask]:
        return self.session.get(EvaluationTask, task_id)

    def get_all_tasks(self) -> List[EvaluationTask]:
        return self.session.exec(select(EvaluationTask)).all()

    # ====================================================
    # ğŸŒŸ æ ¸å¿ƒä¿®æ”¹ï¼šçœŸå®çš„è¯„æµ‹é€»è¾‘
    # ====================================================
    def run_evaluation_logic(self, task_id: int):
        """
        æ‰§è¡Œè¯„æµ‹ä»»åŠ¡ (Real Implementation)
        """
        # 1. è·å–ä»»åŠ¡ä¸ä¸Šä¸‹æ–‡
        task = self.get_task(task_id)
        if not task:
            return "Task Not Found"

        # æ›´æ–°çŠ¶æ€ä¸º Running
        task.status = "running"
        task.progress = 1
        task.error_msg = None
        self.session.add(task)
        self.session.commit()

        try:
            # 2. å‡†å¤‡æ•°æ®å¯¹è±¡
            model = self.session.get(LLMModel, task.model_id)
            if not model:
                raise ValueError(f"Model {task.model_id} not found")

            # è§£ææ•°æ®é›†é…ç½®
            config_ids = []
            try:
                config_ids = json.loads(task.datasets_list)
            except:
                pass
            
            configs = self.session.exec(
                select(DatasetConfig).where(DatasetConfig.id.in_(config_ids))
            ).all()

            if not configs:
                raise ValueError("No datasets found for this task")

            # 3. åˆå§‹åŒ– Runner
            # ä¸ºæ¯ä¸ªä»»åŠ¡åˆ›å»ºä¸€ä¸ªç‹¬ç«‹çš„å·¥ä½œç›®å½•ï¼Œé¿å…å†²çª
            # è·¯å¾„ç¤ºä¾‹: workspace/tasks/task_123
            task_workspace = os.path.join(os.getcwd(), "workspace", "tasks", f"task_{task_id}")
            runner = OpenCompassRunner(workspace=task_workspace)
            
            # æ›´æ–°è¿›åº¦
            task.progress = 5
            self.session.add(task)
            self.session.commit()

            # 4. ç”Ÿæˆé…ç½®æ–‡ä»¶
            print(f"ğŸ“„ [Task {task_id}] Generating config...")
            config_path = runner.generate_config(task_id, model, configs)
            
            task.progress = 10
            self.session.add(task)
            self.session.commit()

            # 5. æ‰§è¡Œè¯„æµ‹ (è¿™æ˜¯ä¸€ä¸ªè€—æ—¶é˜»å¡æ“ä½œ)
            print(f"ğŸš€ [Task {task_id}] Running OpenCompass...")
            # TODO: æœªæ¥å¯ä»¥ä¼ å…¥ callback å‡½æ•°æ¥å®æ—¶æ›´æ–° 10%~90% çš„è¿›åº¦
            runner.run(config_path)
            
            # è¿è¡Œå®Œæˆåï¼Œè¿›åº¦è·³åˆ° 90%
            task.progress = 90
            self.session.add(task)
            self.session.commit()

            # 6. è§£æç»“æœå¹¶å…¥åº“
            print(f"ğŸ“Š [Task {task_id}] Parsing results...")
            raw_results = runner.parse_results()
            
            table_data = [] # ç”¨äºå‰ç«¯å±•ç¤ºçš„æ‘˜è¦è¡¨

            # å»ºç«‹ä¸€ä¸ª config_name -> config å¯¹è±¡çš„æ˜ å°„ï¼Œæ–¹ä¾¿æŸ¥æ‰¾ meta ä¿¡æ¯
            # å‡è®¾ dataset çš„ abbr (OpenCompassè¾“å‡ºçš„datasetåˆ—) ä¸æˆ‘ä»¬çš„ config_name æˆ– name å¯¹åº”
            # è¿™é‡Œåšä¸€ä¸ªæ¨¡ç³ŠåŒ¹é…æˆ–ç®€åŒ–å¤„ç†ï¼šå°è¯•åŒ¹é… config_name æˆ– meta.name
            
            for res in raw_results:
                # å¯»æ‰¾å¯¹åº”çš„ config å¯¹è±¡
                matched_config = None
                dataset_abbr = res['dataset']
                
                for cfg in configs:
                    # OpenCompass çš„ abbr é€šå¸¸ç”±æˆ‘ä»¬ç”Ÿæˆçš„é…ç½®æ–‡ä»¶ä¸­çš„ abbr å­—æ®µå†³å®š
                    # åœ¨ config_factory æˆ– runner ä¸­æˆ‘ä»¬å¯èƒ½ç”¨ name ä½œä¸º abbr
                    # è¿™é‡Œåšä¸€ä¸ªç®€å•çš„åŒ…å«åŒ¹é…
                    if cfg.meta.name in dataset_abbr or dataset_abbr in cfg.meta.name:
                        matched_config = cfg
                        break
                
                # å¦‚æœæ²¡åŒ¹é…åˆ°ï¼Œé€‰ç¬¬ä¸€ä¸ªï¼ˆå…œåº•ï¼‰ï¼Œæˆ–è€…è·³è¿‡
                target_config_id = matched_config.id if matched_config else configs[0].id
                dataset_name_display = matched_config.meta.name if matched_config else dataset_abbr
                dataset_category = matched_config.meta.category if matched_config else "Unknown"
                
                # å†™å…¥æ•°æ®åº“ EvaluationResult
                db_result = EvaluationResult(
                    task_id=task_id,
                    dataset_config_id=target_config_id,
                    dataset_name=dataset_name_display,
                    metric_name=res['metric'],
                    score=res['score'],
                    details=res['raw_data']
                )
                self.session.add(db_result)
                
                # æ”¶é›†å‰ç«¯å±•ç¤ºæ•°æ®
                table_data.append({
                    "dataset": dataset_name_display,
                    "capability": dataset_category,
                    "metric": res['metric'],
                    "score": res['score']
                })

            # 7. ç”Ÿæˆæœ€ç»ˆçš„ä»»åŠ¡æ‘˜è¦ (Radar + Table)
            final_summary = self._generate_summary(table_data)
            
            task.result_summary = json.dumps(final_summary)
            task.status = "success"
            task.progress = 100
            task.finished_at = datetime.now()
            
            print(f"âœ… [Task {task_id}] Finished successfully.")

        except Exception as e:
            import traceback
            traceback.print_exc()
            task.status = "failed"
            task.error_msg = str(e)
            print(f"âŒ [Task {task_id}] Failed: {e}")
        
        finally:
            self.session.add(task)
            self.session.commit()
            return f"Task {task_id} processed"

    def _generate_summary(self, table_data: List[Dict]) -> Dict:
        """
        æ ¹æ®ç»“æœç”Ÿæˆé›·è¾¾å›¾å’Œè¡¨æ ¼æ•°æ®
        """
        if not table_data:
            return {"radar": [], "table": []}

        # 1. è®¡ç®—èƒ½åŠ›ç»´åº¦çš„å¹³å‡åˆ† (Radar Data)
        capability_stats = {}
        for item in table_data:
            cat = item['capability']
            if cat not in capability_stats:
                capability_stats[cat] = []
            capability_stats[cat].append(item['score'])
        
        radar_data = []
        for cat, scores in capability_stats.items():
            avg_score = sum(scores) / len(scores) if scores else 0
            radar_data.append({
                "name": cat,
                "max": 100,
                "score": round(avg_score, 1)
            })
            
        return {
            "radar": radar_data,
            "table": table_data
        }