import json
import time
from celery import Celery
from sqlmodel import Session, select
from app.core.database import engine
from app.models.task import EvaluationTask
# å¼•å…¥æ–°æ¨¡å‹ä»¥è·å–è¯¦ç»†ä¿¡æ¯
from app.models.dataset import DatasetConfig, DatasetMeta

celery_app = Celery(
    "worker",
    broker="redis://localhost:6379/0",
    backend="redis://localhost:6379/0"
)
celery_app.conf.broker_connection_retry_on_startup = True

def _update_task(task_id: int, progress: int = None, status: str = None, result: dict = None):
    with Session(engine) as session:
        task = session.get(EvaluationTask, task_id)
        if task:
            if progress is not None: task.progress = progress
            if status is not None: task.status = status
            if result is not None: task.result_summary = json.dumps(result)
            session.add(task)
            session.commit()

@celery_app.task
def run_evaluation_task(task_id: int):
    print(f"ğŸš€ [Worker] å¼€å§‹æ‰§è¡Œä»»åŠ¡ {task_id}")
    
    # 0. è·å–ä»»åŠ¡ä¿¡æ¯å’Œé…ç½®è¯¦æƒ…
    with Session(engine) as session:
        task = session.get(EvaluationTask, task_id)
        if not task:
            return "Task Not Found"
            
        config_ids = json.loads(task.datasets_list)
        # æŸ¥è¯¢è¯¦ç»†é…ç½®ä¿¡æ¯ç”¨äºç”ŸæˆæŠ¥å‘Š
        configs = session.exec(
            select(DatasetConfig).where(DatasetConfig.id.in_(config_ids))
        ).all()
        
        # é¢„å…ˆå‡†å¤‡å¥½æŠ¥å‘Šç”¨çš„åç§°åˆ—è¡¨
        # æ ¼å¼ç¤ºä¾‹: "GSM8K (gen)", "C-Eval (ppl)"
        report_items = []
        for cfg in configs:
            # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦ç”±äº lazy loadingï¼Œå¯èƒ½éœ€è¦æ‰‹åŠ¨åŠ è½½ metaï¼Œæˆ–è€…ç¡®ä¿ session æ²¡å…³
            # å¦‚æœé…ç½®äº† Relationshipï¼Œå¯ä»¥ç›´æ¥è®¿é—® cfg.meta.name
            dataset_name = cfg.meta.name if cfg.meta else "Unknown"
            report_items.append({
                "name": f"{dataset_name} ({cfg.mode})",
                "capability": cfg.meta.category, # å‡è®¾ category æ˜¯èƒ½åŠ›ç»´åº¦
                "metric": cfg.display_metric
            })

    # 1. åˆå§‹åŒ–
    _update_task(task_id, progress=5, status="running")
    time.sleep(1)
    
    # 2. æ¨¡æ‹ŸåŠ è½½æ¨¡å‹
    _update_task(task_id, progress=20)
    time.sleep(2)
    
    # 3. æ¨¡æ‹Ÿè¯„æµ‹æ•°æ®é›†
    total_steps = len(report_items) # æ ¹æ®å®é™…é€‰æ‹©çš„æ•°æ®é›†æ•°é‡
    if total_steps == 0: total_steps = 1
    
    table_data = []
    
    for i, item in enumerate(report_items):
        # æ›´æ–°è¿›åº¦
        current_progress = 20 + int(((i + 1) / total_steps) * 60)
        _update_task(task_id, progress=current_progress)
        
        time.sleep(1.5) # æ¨¡æ‹Ÿæ¨ç†
        
        # ç”Ÿæˆè¯¥æ•°æ®é›†çš„æ¨¡æ‹Ÿåˆ†æ•°
        import random
        score = round(random.uniform(50, 95), 1)
        
        table_data.append({
            "dataset": item["name"],
            "capability": item["capability"],
            "metric": item["metric"],
            "score": score
        })

    # 4. æ„é€ æœ€ç»ˆç»“æœ 
    final_result = {
        "radar": [
            # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥æ ¹æ® table_data èšåˆ capability åˆ†æ•°
            {"name": "Knowledge", "max": 100, "score": 85.5},
            {"name": "Reasoning", "max": 100, "score": 62.1},
            {"name": "Coding", "max": 100, "score": 78.4},
        ],
        "table": table_data, # ä½¿ç”¨åŠ¨æ€ç”Ÿæˆçš„æ•°æ®
        "files": [
            {"name": "prediction_results.jsonl", "size": "12MB", "type": "json"}
        ]
    }
    
    # 5. å®Œæˆ
    _update_task(task_id, progress=100, status="success", result=final_result)
    print(f"âœ… [Worker] ä»»åŠ¡ {task_id} å®Œæˆ")
    return f"Task {task_id} Success"