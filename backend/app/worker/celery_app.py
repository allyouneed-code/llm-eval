import json
import time
import random #æ¨¡æ‹Ÿç”¨
import os
from celery import Celery
from sqlmodel import Session, select
from app.core.database import engine
from app.models.task import EvaluationTask
# å¼•å…¥æ–°æ¨¡å‹ä»¥è·å–è¯¦ç»†ä¿¡æ¯
from app.models.dataset import DatasetConfig
from app.models.result import EvaluationResult

REDIS_URL = os.getenv("CELERY_BROKER_URL", "redis://localhost:6379/0")

celery_app = Celery(
    "worker",
    broker=REDIS_URL,
    backend=REDIS_URL
)
celery_app.conf.broker_connection_retry_on_startup = True

def _update_task(task_id: int, progress: int = None, status: str = None, result: dict = None):
    with Session(engine) as session:
        task = session.get(EvaluationTask, task_id)
        if task:
            if progress is not None: task.progress = progress
            if status is not None: task.status = status
            if result is not None: task.result_summary = json.dumps(result)
            session.add(task)
            session.commit()

@celery_app.task
def run_evaluation_task(task_id: int):
    print(f"ğŸš€ [Worker] å¼€å§‹æ‰§è¡Œä»»åŠ¡ {task_id}")
    
    # æ‰“å¼€ Sessionï¼Œæ³¨æ„è¿™é‡Œæˆ‘ä»¬æ‰©å¤§äº† Session çš„ä½œç”¨åŸŸï¼Œ
    # ä»¥ä¾¿åœ¨å¾ªç¯ä¸­ç›´æ¥å†™å…¥ EvaluationResult
    with Session(engine) as session:
        # 0. è·å–ä»»åŠ¡ä¿¡æ¯
        task = session.get(EvaluationTask, task_id)
        if not task:
            return "Task Not Found"
            
        config_ids = json.loads(task.datasets_list)
        configs = session.exec(
            select(DatasetConfig).where(DatasetConfig.id.in_(config_ids))
        ).all()
        
        # é¢„å¤„ç†ï¼šæ„å»ºå¾…è¯„æµ‹åˆ—è¡¨ï¼ŒğŸŒŸ å…³é”®ï¼šä¿ç•™ config.id ä»¥ä¾¿å†™å…¥æ•°æ®åº“
        eval_queue = []
        for cfg in configs:
            dataset_name = cfg.meta.name if cfg.meta else f"Dataset-{cfg.id}"
            eval_queue.append({
                "config_id": cfg.id,     # ğŸŒŸ å¿…é¡»ä¼  ID ç»™åç»­å†™å…¥ä½¿ç”¨
                "name": dataset_name,
                "mode": cfg.mode,
                "capability": cfg.meta.category,
                "metric": cfg.display_metric
            })

        # 1. æ›´æ–°çŠ¶æ€
        task.progress = 5
        task.status = "running"
        session.add(task)
        session.commit()
        
        # 2. æ¨¡æ‹ŸåŠ è½½æ¨¡å‹
        time.sleep(1)
        task.progress = 10
        session.add(task)
        session.commit()
        
        # 3. é€ä¸ªè¯„æµ‹æ•°æ®é›†
        total_steps = len(eval_queue)
        table_data = [] # ç”¨äºæœ€åç”Ÿæˆå‰ç«¯å¤§ JSON
        
        for i, item in enumerate(eval_queue):
            # æ¨¡æ‹Ÿæ¨ç†è€—æ—¶
            time.sleep(1.5) 
            
            # æ¨¡æ‹Ÿåˆ†æ•°ç”Ÿæˆ
            score = round(random.uniform(50, 95), 1)
            
            # === ğŸŒŸ æ ¸å¿ƒä¿®æ”¹ Start: å†™å…¥åŸå­åŒ–ç»“æœè¡¨ ===
            db_result = EvaluationResult(
                task_id=task_id,
                dataset_config_id=item["config_id"], # è¿™é‡Œç”¨åˆ°äº†ä¸Šé¢ä¿ç•™çš„ ID
                dataset_name=item["name"],           # å†—ä½™å­˜ä¸ªåå­—
                metric_name=item["metric"],
                score=score,
                details={"full_log": "mock_log_path.txt"} # æ¨¡æ‹Ÿå­˜ä¸€äº›è¯¦æƒ…
            )
            session.add(db_result)
            # === æ ¸å¿ƒä¿®æ”¹ End ===

            # åŒæ—¶ç»´æŠ¤ç»™å‰ç«¯çœ‹çš„ table_data (ä¿æŒæ—§é€»è¾‘å…¼å®¹)
            table_data.append({
                "dataset": f"{item['name']} ({item['mode']})",
                "capability": item["capability"],
                "metric": item["metric"],
                "score": score
            })
            
            # æ›´æ–°è¿›åº¦
            current_progress = 10 + int(((i + 1) / total_steps) * 80)
            task.progress = current_progress
            session.add(task)
            session.commit()

        # 4. æ„é€ æœ€ç»ˆæ‘˜è¦ (Radar + Table)
        # è¿™é‡Œä¾ç„¶ç”Ÿæˆ result_summary æ˜¯ä¸ºäº†è®©å‰ç«¯ Dashboard ä¸ç”¨æ”¹ä»£ç ä¹Ÿèƒ½è·‘
        final_summary = {
            "radar": [
                {"name": "Knowledge", "max": 100, "score": 85.5},
                {"name": "Reasoning", "max": 100, "score": 62.1},
            ],
            "table": table_data 
        }
        
        task.result_summary = json.dumps(final_summary)
        task.status = "success"
        task.progress = 100
        
        session.add(task)
        session.commit()
        
    print(f"âœ… [Worker] ä»»åŠ¡ {task_id} å®Œæˆï¼Œç»“æœå·²å­˜å…¥ evaluation_results è¡¨")
    return f"Task {task_id} Success"