import os
import shutil
import json
import pandas as pd
from fastapi import APIRouter, HTTPException, Depends, UploadFile, File, Form
from fastapi.responses import FileResponse
from sqlmodel import Session, select, func, or_
from sqlalchemy.orm import selectinload 
from typing import List, Optional

from app.core.database import get_session
from app.models.dataset import DatasetMeta, DatasetConfig
from app.schemas.dataset_schema import (
    DatasetMetaRead, DatasetConfigCreate, 
    DatasetPaginationResponse, CategoryStat
)

router = APIRouter()

UPLOAD_DIR = "data/datasets"
os.makedirs(UPLOAD_DIR, exist_ok=True)

# ==========================================
# 1. è¾…åŠ©å‡½æ•°
# ==========================================

def _parse_preview_data(filepath_or_buffer, filename: str):
    """è§£ææ–‡ä»¶å‰å‡ è¡Œç”¨äºé¢„è§ˆ"""
    filename = filename.lower()
    df = None
    try:
        if filename.endswith(".csv"):
            df = pd.read_csv(filepath_or_buffer, nrows=5, on_bad_lines='skip')
        elif filename.endswith(".json"):
            df = pd.read_json(filepath_or_buffer)
            df = df.head(5)
        elif filename.endswith(".jsonl"):
            with pd.read_json(filepath_or_buffer, lines=True, chunksize=5) as reader:
                for chunk in reader:
                    df = chunk
                    break
        elif filename.endswith(".xlsx") or filename.endswith(".xls"):
            df = pd.read_excel(filepath_or_buffer, nrows=5)
        
        if df is not None:
            df = df.where(pd.notnull(df), None)
            return {
                "columns": list(df.columns),
                "rows": df.to_dict(orient="records")
            }
    except Exception as e:
        print(f"Parse Error: {e}")
    return {"columns": [], "rows": []}

def _extract_metric_name(eval_cfg_json: str, default: str = "Accuracy") -> str:
    """ä» metric_config JSON ä¸­æå–ä¸»è¦çš„æŒ‡æ ‡åç§°"""
    try:
        data = json.loads(eval_cfg_json)
        evaluator = data.get('evaluator', {})
        etype = evaluator.get('type') if isinstance(evaluator, dict) else evaluator
        
        s_type = str(etype)
        if 'AccEvaluator' in s_type: return 'Accuracy'
        if 'BleuEvaluator' in s_type: return 'BLEU'
        if 'RougeEvaluator' in s_type: return 'ROUGE'
        if 'ToxicEvaluator' in s_type: return 'Toxicity'
        if 'Pass' in s_type or 'Code' in s_type: return 'Pass@k'
        return default
    except:
        return default

# ==========================================
# 2. é¢„è§ˆä¸ä¸‹è½½æ¥å£
# ==========================================

@router.post("/preview")
def preview_dataset(file: UploadFile = File(...)):
    return _parse_preview_data(file.file, file.filename)

@router.get("/{meta_id}/preview")
def preview_saved_dataset(meta_id: int, session: Session = Depends(get_session)):
    meta = session.get(DatasetMeta, meta_id)
    if not meta or not meta.configs:
        raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°ç›¸å…³æ•°æ®æ–‡ä»¶")
    
    config = meta.configs[0]
    if not os.path.exists(config.file_path):
        raise HTTPException(status_code=404, detail="æ–‡ä»¶åœ¨ç£ç›˜ä¸Šä¸å­˜åœ¨")
    
    return _parse_preview_data(config.file_path, config.file_path)

@router.get("/{meta_id}/download")
def download_dataset_file(meta_id: int, session: Session = Depends(get_session)):
    meta = session.get(DatasetMeta, meta_id)
    if not meta or not meta.configs:
        raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°æ–‡ä»¶")
    
    config = meta.configs[0]
    if not os.path.exists(config.file_path):
        raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")
    
    filename = os.path.basename(config.file_path)
    return FileResponse(path=config.file_path, filename=filename, media_type='application/octet-stream')

# ==========================================
# 3. æ ¸å¿ƒæ¥å£ï¼šåˆ›å»ºä¸è¯»å– (å·²é‡æ„æ”¯æŒå¤šé…ç½®)
# ==========================================

@router.get("/stats", response_model=List[CategoryStat])
def get_dataset_stats(session: Session = Depends(get_session)):
    statement = select(DatasetMeta.category, func.count(DatasetMeta.id)).group_by(DatasetMeta.category)
    results = session.exec(statement).all()
    stats = [{"category": row[0], "count": row[1]} for row in results]
    return stats

@router.post("/", response_model=DatasetMetaRead)
def create_dataset(
    name: str = Form(...),
    category: str = Form(...),
    description: Optional[str] = Form(None),
    
    # ğŸ”„ å˜æ›´ï¼šæ¥æ”¶ JSON åˆ—è¡¨å­—ç¬¦ä¸²ï¼Œä¸å†æ¥æ”¶æ•£è£…å‚æ•°
    # æ ¼å¼ç¤ºä¾‹ï¼š[{"config_name": "v1", "mode": "gen", "reader_cfg": "...", "post_process_cfg": "..."}]
    configs_json: str = Form(...), 
    
    file: UploadFile = File(...),
    session: Session = Depends(get_session)
):
    """
    åˆ›å»ºæ•°æ®é›† (Meta) + æ‰¹é‡åˆ›å»ºé…ç½® (Configs) + ä¸Šä¼ æ–‡ä»¶
    """
    
    # 1. æ£€æŸ¥æˆ–åˆ›å»ºå…ƒæ•°æ® (DatasetMeta)
    statement = select(DatasetMeta).where(DatasetMeta.name == name)
    meta = session.exec(statement).first()
    
    if not meta:
        meta = DatasetMeta(
            name=name,
            category=category,
            description=description
        )
        session.add(meta)
        session.commit()
        session.refresh(meta)
    
    # 2. ä¿å­˜æ–‡ä»¶ (ç‰©ç†å­˜å‚¨)
    # ä¼˜åŒ–ï¼šæ–‡ä»¶åä¸å†ç»‘å®š modeï¼Œæ”¹ä¸º base æˆ–ç›´æ¥ä½¿ç”¨åŸå§‹æ‰©å±•å
    file_ext = os.path.splitext(file.filename)[1]
    save_name = f"{name}_base{file_ext}" # ä½¿ç”¨ _base åç¼€è¡¨ç¤ºè¿™æ˜¯é€šç”¨æºæ–‡ä»¶
    save_path = os.path.join(UPLOAD_DIR, save_name)
    abs_path = os.path.abspath(save_path)
    
    file.file.seek(0)
    with open(save_path, "wb") as buffer:
        shutil.copyfileobj(file.file, buffer)
        
    # 3. è§£æå¹¶æ‰¹é‡å¤„ç†é…ç½®
    try:
        configs_list = json.loads(configs_json)
        if not isinstance(configs_list, list):
            raise ValueError("configs_json must be a list")
    except Exception as e:
        # å¦‚æœè§£æå¤±è´¥ï¼Œæ¸…ç†åˆšä¸Šä¼ çš„æ–‡ä»¶ï¼ˆå¦‚æœæ˜¯æ–°å»ºçš„ï¼‰
        # è¿™é‡Œç®€å•èµ·è§æš‚ä¸åˆ é™¤ï¼Œå› ä¸º meta å¯èƒ½å·²å­˜åœ¨
        raise HTTPException(status_code=400, detail=f"é…ç½®æ ¼å¼é”™è¯¯: {str(e)}")

    processed_count = 0
    errors = []

    for cfg_data in configs_list:
        try:
            # A. è‡ªåŠ¨è¡¥å…¨å¿…è¦å­—æ®µ
            cfg_data["meta_id"] = meta.id
            cfg_data["file_path"] = abs_path
            
            # B. ç¡®ä¿ config_name å­˜åœ¨ï¼Œè‹¥æ— åˆ™è‡ªåŠ¨ç”Ÿæˆ
            if not cfg_data.get("config_name"):
                mode_suffix = cfg_data.get("mode", "gen")
                cfg_data["config_name"] = f"{name}_{mode_suffix}"
                
            # C. è‡ªåŠ¨æå– Display Metric (å¦‚æœå‰ç«¯æ²¡ä¼ )
            if not cfg_data.get("display_metric"):
                cfg_data["display_metric"] = _extract_metric_name(
                    cfg_data.get("metric_config", "{}")
                )

            # D. Pydantic æ ¡éªŒ (åŒ…å«å¯¹ post_process_cfg ç­‰æ–°å­—æ®µçš„æ ¡éªŒ)
            validated_config = DatasetConfigCreate(**cfg_data)
            
            # E. æŸ¥é‡ä¸å…¥åº“
            # æ£€æŸ¥è¯¥ Meta ä¸‹æ˜¯å¦å·²å­˜åœ¨åŒåé…ç½®
            existing = next((c for c in meta.configs if c.config_name == validated_config.config_name), None)
            
            if existing:
                # æ›´æ–°æ¨¡å¼
                existing.mode = validated_config.mode
                existing.file_path = validated_config.file_path # æ›´æ–°è·¯å¾„
                existing.reader_cfg = validated_config.reader_cfg
                existing.infer_cfg = validated_config.infer_cfg
                existing.metric_config = validated_config.metric_config
                existing.display_metric = validated_config.display_metric
                
                # ğŸ†• æ›´æ–°æ–°å­—æ®µ
                existing.post_process_cfg = validated_config.post_process_cfg
                existing.few_shot_cfg = validated_config.few_shot_cfg
                
                session.add(existing)
            else:
                # åˆ›å»ºæ¨¡å¼
                db_config = DatasetConfig(**validated_config.model_dump())
                session.add(db_config)
            
            processed_count += 1
            
        except Exception as e:
            errors.append(f"Config '{cfg_data.get('config_name', 'unknown')}': {str(e)}")
            continue

    if processed_count == 0 and errors:
        # å¦‚æœä¸€ä¸ªéƒ½æ²¡æˆåŠŸï¼ŒæŠ›å‡ºç¬¬ä¸€ä¸ªé”™è¯¯
        raise HTTPException(status_code=400, detail=f"å¯¼å…¥å¤±è´¥: {errors[0]}")

    session.commit()
    session.refresh(meta)
    return meta

@router.get("/", response_model=DatasetPaginationResponse)
def read_datasets(
    session: Session = Depends(get_session),
    page: int = 1,
    page_size: int = 10,
    category: Optional[str] = None,
    keyword: Optional[str] = None,
    private_only: bool = False
):
    offset = (page - 1) * page_size
    
    query = select(DatasetMeta)
    
    if category and category != 'All':
        query = query.where(DatasetMeta.category == category)
    
    if keyword:
        query = query.where(
            or_(
                DatasetMeta.name.contains(keyword),
                DatasetMeta.description.contains(keyword)
            )
        )
    
    if private_only:
        query = query.join(DatasetConfig).where(DatasetConfig.file_path.not_like("official://%"))
        
    count_statement = select(func.count()).select_from(query.subquery())
    total = session.exec(count_statement).one()
    
    query = query.options(selectinload(DatasetMeta.configs))
    query = query.offset(offset).limit(page_size)
    items = session.exec(query).unique().all()
    
    return DatasetPaginationResponse(total=total, items=items)

@router.delete("/{meta_id}")
def delete_dataset(meta_id: int, session: Session = Depends(get_session)):
    meta = session.get(DatasetMeta, meta_id)
    if not meta:
        raise HTTPException(status_code=404, detail="Dataset not found")
    
    for config in meta.configs:
        if os.path.exists(config.file_path):
            try:
                os.remove(config.file_path)
            except:
                pass
        
    session.delete(meta)
    session.commit()
    return {"ok": True}