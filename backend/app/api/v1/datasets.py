import os
import shutil
import json
import pandas as pd
from fastapi import APIRouter, HTTPException, Depends, UploadFile, File, Form
from fastapi.responses import FileResponse
from sqlmodel import Session, select, func, or_
from sqlalchemy.orm import selectinload 
from typing import List, Optional

from app.core.database import get_session
from app.models.dataset import DatasetMeta, DatasetConfig
# å¼•å…¥æ–°å®šä¹‰çš„ Schema
from app.schemas.dataset_schema import (
    DatasetMetaRead, DatasetConfigCreate, 
    DatasetPaginationResponse, CategoryStat
)

router = APIRouter()

UPLOAD_DIR = "data/datasets"
os.makedirs(UPLOAD_DIR, exist_ok=True)

# ==========================================
# 1. è¾…åŠ©å‡½æ•°
# ==========================================

def _parse_preview_data(filepath_or_buffer, filename: str):
    """è§£ææ–‡ä»¶å‰å‡ è¡Œç”¨äºé¢„è§ˆ"""
    filename = filename.lower()
    df = None
    try:
        if filename.endswith(".csv"):
            df = pd.read_csv(filepath_or_buffer, nrows=5, on_bad_lines='skip')
        elif filename.endswith(".json"):
            df = pd.read_json(filepath_or_buffer)
            df = df.head(5)
        elif filename.endswith(".jsonl"):
            with pd.read_json(filepath_or_buffer, lines=True, chunksize=5) as reader:
                for chunk in reader:
                    df = chunk
                    break
        elif filename.endswith(".xlsx") or filename.endswith(".xls"):
            df = pd.read_excel(filepath_or_buffer, nrows=5)
        
        if df is not None:
            df = df.where(pd.notnull(df), None)
            return {
                "columns": list(df.columns),
                "rows": df.to_dict(orient="records")
            }
    except Exception as e:
        print(f"Parse Error: {e}")
    return {"columns": [], "rows": []}

def _extract_metric_name(eval_cfg_json: str, default: str = "Accuracy") -> str:
    """ä» metric_config JSON ä¸­æå–ä¸»è¦çš„æŒ‡æ ‡åç§°"""
    try:
        data = json.loads(eval_cfg_json)
        # å…¼å®¹æ–‡æ¡£ä¸­çš„ç»“æ„: evaluator -> type æˆ– evaluator: "AccEvaluator"
        evaluator = data.get('evaluator', {})
        etype = evaluator.get('type') if isinstance(evaluator, dict) else evaluator
        
        # ç®€å•çš„æ˜ å°„è¡¨
        s_type = str(etype)
        if 'AccEvaluator' in s_type: return 'Accuracy'
        if 'BleuEvaluator' in s_type: return 'BLEU'
        if 'RougeEvaluator' in s_type: return 'ROUGE'
        if 'ToxicEvaluator' in s_type: return 'Toxicity'
        if 'Pass' in s_type or 'Code' in s_type: return 'Pass@k'
        return default
    except:
        return default

# ==========================================
# 2. é¢„è§ˆä¸ä¸‹è½½æ¥å£
# ==========================================

@router.post("/preview")
def preview_dataset(file: UploadFile = File(...)):
    return _parse_preview_data(file.file, file.filename)

@router.get("/{meta_id}/preview")
def preview_saved_dataset(meta_id: int, session: Session = Depends(get_session)):
    """é¢„è§ˆæ•°æ®é›†ï¼šé»˜è®¤é¢„è§ˆè¯¥æ•°æ®é›†ä¸‹çš„ç¬¬ä¸€ä¸ªé…ç½®å¯¹åº”çš„æ–‡ä»¶"""
    meta = session.get(DatasetMeta, meta_id)
    if not meta or not meta.configs:
        raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°ç›¸å…³æ•°æ®æ–‡ä»¶")
    
    config = meta.configs[0]
    if not os.path.exists(config.file_path):
        raise HTTPException(status_code=404, detail="æ–‡ä»¶åœ¨ç£ç›˜ä¸Šä¸å­˜åœ¨")
    
    return _parse_preview_data(config.file_path, config.file_path)

@router.get("/{meta_id}/download")
def download_dataset_file(meta_id: int, session: Session = Depends(get_session)):
    meta = session.get(DatasetMeta, meta_id)
    if not meta or not meta.configs:
        raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°æ–‡ä»¶")
    
    config = meta.configs[0]
    if not os.path.exists(config.file_path):
        raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")
    
    filename = os.path.basename(config.file_path)
    return FileResponse(path=config.file_path, filename=filename, media_type='application/octet-stream')

# ==========================================
# 3. æ ¸å¿ƒæ¥å£ï¼šåˆ›å»ºä¸è¯»å–
# ==========================================

@router.get("/stats", response_model=List[CategoryStat])
def get_dataset_stats(session: Session = Depends(get_session)):
    """è·å–æ¯ä¸ªåˆ†ç±»ä¸‹çš„æ•°æ®é›†æ•°é‡"""
    # SQL: SELECT category, COUNT(*) FROM dataset_metas GROUP BY category
    statement = select(DatasetMeta.category, func.count(DatasetMeta.id)).group_by(DatasetMeta.category)
    results = session.exec(statement).all()
    
    stats = [{"category": row[0], "count": row[1]} for row in results]
    return stats

@router.post("/", response_model=DatasetMetaRead)
def create_dataset(
    name: str = Form(...),
    category: str = Form(...),
    description: Optional[str] = Form(None),
    
    # === é…ç½®ç›¸å…³å­—æ®µ ===
    mode: str = Form("gen"),
    # æ¥æ”¶å®Œæ•´çš„ JSON å­—ç¬¦ä¸²é…ç½®
    reader_cfg: str = Form('{"input_columns":["input"], "output_column":"target"}'), 
    infer_cfg: str = Form('{}'),
    metric_config: str = Form('{"evaluator": {"type": "AccEvaluator"}}'),
    
    file: UploadFile = File(...),
    session: Session = Depends(get_session)
):
    """
    åˆ›å»ºæ•°æ®é›† (Meta) + é»˜è®¤é…ç½® (Config) + ä¸Šä¼ æ–‡ä»¶
    æ­¤å¤„é›†æˆäº† Pydantic æ ¡éªŒé€»è¾‘
    """
    
    # 1. æ£€æŸ¥æˆ–åˆ›å»ºå…ƒæ•°æ® (DatasetMeta)
    statement = select(DatasetMeta).where(DatasetMeta.name == name)
    meta = session.exec(statement).first()
    
    if not meta:
        meta = DatasetMeta(
            name=name,
            category=category,
            description=description
        )
        session.add(meta)
        session.commit()
        session.refresh(meta)
    
    # 2. ä¿å­˜æ–‡ä»¶ (ç‰©ç†å­˜å‚¨)
    file_ext = os.path.splitext(file.filename)[1]
    save_name = f"{name}_{mode}{file_ext}"
    save_path = os.path.join(UPLOAD_DIR, save_name)
    abs_path = os.path.abspath(save_path)
    
    file.file.seek(0)
    with open(save_path, "wb") as buffer:
        shutil.copyfileobj(file.file, buffer)
        
    # 3. å‡†å¤‡é…ç½®æ•°æ®
    # ğŸŒŸ è‡ªåŠ¨æå– Display Metric
    auto_metric = _extract_metric_name(metric_config, default="Accuracy")
    
    config_data = {
        "meta_id": meta.id,
        "config_name": f"{name}_{mode}",
        "mode": mode,
        "file_path": abs_path,
        "reader_cfg": reader_cfg,
        "infer_cfg": infer_cfg,
        "metric_config": metric_config,
        "display_metric": auto_metric
    }

    # 4. ğŸŒŸ æ‰§è¡Œ Pydantic æ ¡éªŒ
    # å¦‚æœ reader_cfg ç¼ºå°‘å­—æ®µï¼Œæˆ– JSON æ ¼å¼é”™è¯¯ï¼Œè¿™é‡Œä¼šç›´æ¥æŠ›å‡º 422 é”™è¯¯
    try:
        validated_config = DatasetConfigCreate(**config_data)
    except ValueError as e:
        # åˆ é™¤å·²ä¸Šä¼ çš„åƒåœ¾æ–‡ä»¶
        if os.path.exists(save_path):
            os.remove(save_path)
        raise HTTPException(status_code=400, detail=f"é…ç½®æ ¡éªŒå¤±è´¥: {str(e)}")

    # 5. å­˜å…¥æ•°æ®åº“
    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨åŒååŒæ¨¡å¼çš„é…ç½®
    existing_config = next((c for c in meta.configs if c.mode == mode), None)
    
    if existing_config:
        # æ›´æ–°ç°æœ‰é…ç½®
        existing_config.file_path = validated_config.file_path
        existing_config.reader_cfg = validated_config.reader_cfg
        existing_config.infer_cfg = validated_config.infer_cfg
        existing_config.metric_config = validated_config.metric_config
        existing_config.display_metric = validated_config.display_metric
        session.add(existing_config)
    else:
        # åˆ›å»ºæ–°é…ç½®
        # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨ validated_config.dict() æ¥ç¡®ä¿ä½¿ç”¨çš„æ˜¯æ¸…æ´—åçš„æ•°æ®
        # ä½† exclude è¯¥ model ä¸åŒ…å«çš„å­—æ®µ (å¦‚ meta_id å·²ç»åœ¨ db model é‡Œå®šä¹‰äº†)
        db_config = DatasetConfig(**validated_config.model_dump())
        session.add(db_config)
    
    session.commit()
    session.refresh(meta)
    return meta

@router.get("/", response_model=DatasetPaginationResponse)
def read_datasets(
    session: Session = Depends(get_session),
    page: int = 1,
    page_size: int = 10,
    category: Optional[str] = None,
    keyword: Optional[str] = None,
    private_only: bool = False
):
    offset = (page - 1) * page_size
    
    # 1. æ„å»ºåŸºç¡€æŸ¥è¯¢
    query = select(DatasetMeta)
    
    # 2. åŠ¨æ€è¿‡æ»¤
    if category and category != 'All':
        query = query.where(DatasetMeta.category == category)
    
    if keyword:
        # æ¨¡ç³Šæœç´¢åç§°æˆ–æè¿°
        query = query.where(
            or_(
                DatasetMeta.name.contains(keyword),
                DatasetMeta.description.contains(keyword)
            )
        )
    
    # å¤„ç† "åªçœ‹ç§æœ‰" é€»è¾‘
    # è¿™é‡Œçš„é€»è¾‘æ˜¯ï¼šè¿æ¥ DatasetConfigï¼ŒæŸ¥æ‰¾è·¯å¾„ä¸­åŒ…å« data/datasets çš„è®°å½•
    if private_only:
        query = query.join(DatasetConfig).where(DatasetConfig.file_path.contains("data/datasets"))
        
    # 3. è·å–æ€»æ•° (Total Count)
    # æ³¨æ„ï¼šä¸ºäº†æ€§èƒ½ï¼Œè¿™é‡Œåº”è¯¥å•ç‹¬æŸ¥ countï¼Œè€Œä¸æ˜¯æŸ¥å‡ºæ‰€æœ‰æ•°æ®å† len()
    # ä½¿ç”¨ func.count() åŒ…è£…å­æŸ¥è¯¢æˆ–è€…ç›´æ¥æŸ¥ id
    # ç®€ä¾¿èµ·è§ï¼Œæˆ‘ä»¬å…ˆç”¨ç®€å•çš„æ–¹å¼ï¼Œå¦‚æœæ•°æ®é‡æå¤§éœ€è¿›ä¸€æ­¥ä¼˜åŒ– count æŸ¥è¯¢
    count_statement = select(func.count()).select_from(query.subquery())
    total = session.exec(count_statement).one()
    
    # 4. åº”ç”¨åˆ†é¡µä¸é¢„åŠ è½½
    # selectinload è§£å†³äº† N+1 é—®é¢˜ï¼Œä¸€æ¬¡æ€§æŠŠ configs æŠ“å‡ºæ¥
    query = query.options(selectinload(DatasetMeta.configs))
    query = query.offset(offset).limit(page_size)
    
    # ç¡®ä¿å”¯ä¸€æ€§ (å› ä¸º join å¯èƒ½å¯¼è‡´é‡å¤ï¼Œè™½ç„¶ SQLModel é€šå¸¸å¤„ç†å¾—å¾ˆå¥½)
    # å¦‚æœ private_only ç”¨äº† joinï¼Œè¿™é‡Œ unique() å¾ˆé‡è¦
    items = session.exec(query).unique().all()
    
    return DatasetPaginationResponse(total=total, items=items)

@router.delete("/{meta_id}")
def delete_dataset(meta_id: int, session: Session = Depends(get_session)):
    meta = session.get(DatasetMeta, meta_id)
    if not meta:
        raise HTTPException(status_code=404, detail="Dataset not found")
    
    # çº§è”åˆ é™¤æ–‡ä»¶
    for config in meta.configs:
        if os.path.exists(config.file_path):
            try:
                os.remove(config.file_path)
            except:
                pass
        
    session.delete(meta)
    session.commit()
    return {"ok": True}