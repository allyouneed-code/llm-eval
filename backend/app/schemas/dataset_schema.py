import json
from typing import Optional, List
from datetime import datetime
from sqlmodel import SQLModel
from pydantic import field_validator, model_validator

# ==========================================
# Level 3: è¯„ä¼°æŒ‡æ ‡ (Metric)
# ==========================================
class EvaluationMetricBase(SQLModel):
    evaluator_type: str
    name: str
    eval_cfg: str = "{}"

class EvaluationMetricRead(EvaluationMetricBase):
    id: int

# ==========================================
# Level 2: è¯„æµ‹é…ç½® (Config)
# ==========================================
class DatasetConfigBase(SQLModel):
    config_name: str
    mode: str = "gen" # gen / ppl
    prompt_version: Optional[str] = None
    
    # ğŸŒŸ UIå±•ç¤ºç”¨çš„æŒ‡æ ‡åç§° (å¦‚ "Accuracy", "BLEU")
    # API åˆ›å»ºæ—¶ä¼šè‡ªåŠ¨æ ¹æ® metric_config è¦†ç›–æ­¤å­—æ®µï¼Œä½†åœ¨ Base é‡Œä¿ç•™é»˜è®¤å€¼
    display_metric: str = "Accuracy"
    
    # é…ç½®è¯¦æƒ… (JSON å­—ç¬¦ä¸²)
    reader_cfg: str = "{}"
    infer_cfg: str = "{}"
    metric_config: str = "{}" # å¯¹åº” evaluator_config

# ğŸŒŸ æ–°å¢ï¼šç”¨äºåˆ›å»ºé…ç½®çš„ Schemaï¼ŒåŒ…å«æ ¡éªŒé€»è¾‘
class DatasetConfigCreate(DatasetConfigBase):
    meta_id: int
    file_path: str  # å¿…é¡»æŒ‡å®šæ–‡ä»¶è·¯å¾„

    # --- æ ¡éªŒ 1: ç¡®ä¿æ‰€æœ‰ cfg å­—æ®µéƒ½æ˜¯åˆæ³•çš„ JSON ---
    @field_validator('reader_cfg', 'infer_cfg', 'metric_config')
    def must_be_valid_json(cls, v):
        try:
            parsed = json.loads(v)
            if not isinstance(parsed, dict):
                raise ValueError("Content must be a JSON object (dict)")
            return v
        except json.JSONDecodeError:
            raise ValueError("Invalid JSON string format")

    # --- æ ¡éªŒ 2: Reader å¿…é¡»åŒ…å«è¾“å…¥è¾“å‡ºå®šä¹‰ ---
    @field_validator('reader_cfg')
    def validate_reader(cls, v):
        try:
            cfg = json.loads(v)
            if 'input_columns' not in cfg or 'output_column' not in cfg:
                raise ValueError("Reader Config must contain 'input_columns' and 'output_column'")
        except:
            pass # ä¸Šé¢çš„ JSON æ ¡éªŒä¼šå…ˆæ‹¦æˆªï¼Œè¿™é‡Œå¿½ç•¥è§£æé”™è¯¯
        return v

    # --- æ ¡éªŒ 3: PPL æ¨¡å¼ä¸‹çš„ç‰¹æ®Šé€»è¾‘ ---
    @model_validator(mode='after')
    def validate_mode_logic(self):
        if self.mode == 'ppl':
            try:
                infer_data = json.loads(self.infer_cfg)
                # å…¼å®¹ä¸åŒå±‚çº§ç»“æ„ï¼Œè¿™é‡Œå‡è®¾æ ‡å‡†ç»“æ„æ˜¯ prompt_template -> template
                # å¦‚æœç»“æ„ä¸åŒï¼Œéœ€æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´
                prompt_cfg = infer_data.get('prompt_template', {})
                template = prompt_cfg.get('template')
                
                # å¦‚æœå–ä¸åˆ° templateï¼Œå¯èƒ½æ˜¯ç»“æ„å·®å¼‚ï¼Œæš‚ä¸å¼ºè¡ŒæŠ¥é”™ï¼Œé˜²æ­¢è¯¯æ€
                if template and not isinstance(template, dict):
                    raise ValueError("In PPL mode, prompt_template.template must be a dictionary mapping options to prompts (e.g., {'0': '...', '1': '...'})")
            except Exception as e:
                # åªåœ¨æ˜ç¡®è§£æå¤±è´¥æˆ–ç±»å‹é”™è¯¯æ—¶æŠ¥é”™
                if "dictionary" in str(e):
                    raise e
        return self

class DatasetConfigRead(DatasetConfigBase):
    id: int
    created_at: datetime = datetime.utcnow()
    # file_path é€šå¸¸ä¸è¿”å›ç»™å‰ç«¯ï¼Œæˆ–æ ¹æ®éœ€è¦è¿”å›
    
    metrics: List[EvaluationMetricRead] = []

# ==========================================
# Level 1: æ•°æ®é›†å…ƒæ•°æ® (Meta)
# ==========================================
class DatasetMetaBase(SQLModel):
    name: str
    category: str = "Base"
    description: Optional[str] = None

class DatasetMetaCreate(DatasetMetaBase):
    pass

class DatasetMetaRead(DatasetMetaBase):
    id: int
    created_at: datetime
    
    # ğŸŒŸ å…³é”®ï¼šåœ¨åˆ—è¡¨é¡µç›´æ¥è¿”å› configs
    configs: List[DatasetConfigRead] = []

class DatasetMetaDetail(DatasetMetaRead):
    pass