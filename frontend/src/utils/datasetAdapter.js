/**
 * src/utils/datasetAdapter.js
 * ä¿®å¤ç‰ˆï¼šå¢žåŠ äº†å¯¹å¤šæ¨¡æ€æ•°æ®é›†çš„è‡ªåŠ¨æ˜ å°„æ”¯æŒ
 */

// ==========================================
// 1. æ ¸å¿ƒå®šä¹‰
// ==========================================

export const TASK_TYPES = {
  CHOICE: { 
    label: 'å®¢è§‚é€‰æ‹©é¢˜ (Multiple Choice)', 
    value: 'choice',
    desc: 'é€‚ç”¨äºŽ MMLU, CMMLU, ARC ç­‰æœ‰æ ‡å‡†é€‰é¡¹(A/B/C/D)çš„é¢˜ç›®'
  },
  QA: { 
    label: 'å¼€æ”¾å¼é—®ç­” (Open QA)', 
    value: 'qa',
    desc: 'é€‚ç”¨äºŽç¿»è¯‘ã€æ‘˜è¦ã€ç®€ç­”ç­‰ç”Ÿæˆå¼ä»»åŠ¡'
  }
}

export const TASK_SLOTS = {
  [TASK_TYPES.CHOICE.value]: [
    { key: 'question', label: 'é¢˜ç›® (Question)', required: true },
    { key: 'optA', label: 'é€‰é¡¹ A', required: true },
    { key: 'optB', label: 'é€‰é¡¹ B', required: true },
    { key: 'optC', label: 'é€‰é¡¹ C', required: false },
    { key: 'optD', label: 'é€‰é¡¹ D', required: false },
    { key: 'answer', label: 'æ ‡å‡†ç­”æ¡ˆ (Key)', required: true }
  ],
  [TASK_TYPES.QA.value]: [
    { key: 'prompt', label: 'è¾“å…¥/æç¤ºè¯ (Input)', required: true },
    { key: 'target', label: 'å‚è€ƒç­”æ¡ˆ (Target)', required: true }
  ]
}

export const TASK_METRICS = {
  [TASK_TYPES.CHOICE.value]: [
    { label: 'Accuracy (å‡†ç¡®çŽ‡)', value: 'Accuracy', default: true },
    { label: 'F1 Score (åŠ æƒå¾—åˆ†)', value: 'F1', default: false }
  ],
  [TASK_TYPES.QA.value]: [
    { label: 'ROUGE-L (æ–‡æœ¬ç›¸ä¼¼åº¦)', value: 'ROUGE', default: true },
    { label: 'BLEU-4 (æœºå™¨ç¿»è¯‘æ ‡å‡†)', value: 'BLEU', default: false },
    { label: 'Exact Match (å®Œå…¨åŒ¹é…)', value: 'EM', default: false }
  ]
}

// â¬‡ï¸ å…¼å®¹æ€§å¯¼å‡º
export const CHOICE_POST_PROCESSORS = [
  { label: 'æå–é¦–é€‰é¡¹ (A/B/C/D)', value: 'first_option' }
]
export const QA_POST_PROCESSORS = []

// ==========================================
// 2. è‡ªåŠ¨æ˜ å°„é€»è¾‘ (Auto-Mapping)
// ==========================================

const METRIC_EVALUATOR_MAP = {
  'Accuracy': 'AccEvaluator',
  'F1': 'F1Evaluator',
  'ROUGE': 'RougeEvaluator',
  'BLEU': 'BleuEvaluator',
  'EM': 'EMEvaluator'
}

function getAutoPostProcessCfg(metric, taskType) {
  if (taskType === TASK_TYPES.CHOICE.value) {
    if (metric === 'Accuracy' || metric === 'F1') {
      return { 
        type: 'opencompass.utils.text_postprocessors.first_option_postprocess',
        options: 'ABCD'
      }
    }
  }
  return null
}

function generatePromptTemplate(taskType, mapping) {
  if (taskType === TASK_TYPES.CHOICE.value) {
    let template = `Question: {${mapping.question}}\n`
    if (mapping.optA) template += `A. {${mapping.optA}}\n`
    if (mapping.optB) template += `B. {${mapping.optB}}\n`
    if (mapping.optC) template += `C. {${mapping.optC}}\n`
    if (mapping.optD) template += `D. {${mapping.optD}}\n`
    template += `Answer:`
    return template
  }
  if (taskType === TASK_TYPES.QA.value) {
    return `Question: {${mapping.prompt}}\nAnswer:`
  }
  return ''
}

// ==========================================
// 3. å·¥åŽ‚æ–¹æ³•
// ==========================================

export function generateConfigPayload(importState) {
  // ðŸŒŸ 1. è§£æž„ importStateï¼Œæ³¨æ„è¿™é‡Œå¢žåŠ äº† modality
  const { meta, taskType, columnMapping, metrics, modality } = importState
  
  // ðŸŒŸ 2. æž„é€  finalMapping (æ ¸å¿ƒä¿®å¤ç‚¹)
  // å¦‚æžœæ˜¯å¤šæ¨¡æ€æ¨¡å¼(éžText)ä¸”æ˜ å°„ä¸ºç©º(å› ä¸ºè·³è¿‡äº†Mappingæ­¥éª¤)ï¼Œåˆ™è‡ªåŠ¨å¡«å……é»˜è®¤å€¼
  let finalMapping = { ...columnMapping }
  
  if (modality && modality !== 'Text' && Object.keys(finalMapping).length === 0) {
      if (taskType === TASK_TYPES.QA.value) {
          // å¤šæ¨¡æ€ QA é»˜è®¤æ˜ å°„
          finalMapping = {
              prompt: 'question', // æ ‡å‡†å­—æ®µ question -> æ˜ å°„åˆ° Input æ’æ§½
              target: 'answer'    // æ ‡å‡†å­—æ®µ answer   -> æ˜ å°„åˆ° Target æ’æ§½
          }
          // æ ¹æ®æ¨¡æ€è¿½åŠ èµ„æºå­—æ®µï¼Œç¡®ä¿å®ƒä»¬è¢«åŠ å…¥ input_columns
          if (modality === 'Image') finalMapping.image = 'image'
          if (modality === 'Video') finalMapping.video = 'video'
          if (modality === 'Audio') finalMapping.audio = 'audio'
      }
      // å¦‚æžœå°†æ¥æ”¯æŒ Choiceï¼Œå¯åœ¨æ­¤å¤„æ‰©å±•
  }

  // ðŸŒŸ 3. Reader Config (ä½¿ç”¨ finalMapping)
  const inputColumns = Object.values(finalMapping).filter(v => v)
  const outputColumnKey = taskType === TASK_TYPES.CHOICE.value ? 'answer' : 'target'
  const outputColumn = finalMapping[outputColumnKey]

  const readerCfg = {
    input_columns: inputColumns,
    output_column: outputColumn,
    mapping: finalMapping 
  }

  // ðŸŒŸ 4. Infer Config (ä½¿ç”¨ finalMapping ç”Ÿæˆ Prompt)
  const promptTemplateStr = generatePromptTemplate(taskType, finalMapping)
  const inferCfg = {
    prompt_template: {
      type: 'PromptTemplate',
      template: promptTemplateStr
    },
    retriever: { type: 'ZeroRetriever' },
    inferencer: { type: 'GenInferencer' }
  }

  // 5. Generate Configs List
  const configs = metrics.map((metricName) => {
    const evaluatorType = METRIC_EVALUATOR_MAP[metricName] || 'AccEvaluator'
    const evaluatorConfig = { type: evaluatorType }
    const postProcessCfg = getAutoPostProcessCfg(metricName, taskType) || {}
    
    return {
      config_name: `${meta.name}_${metricName}`,
      mode: 'gen', 
      display_metric: metricName,
      
      reader_cfg: JSON.stringify(readerCfg),
      infer_cfg: JSON.stringify(inferCfg),
      metric_config: JSON.stringify({ evaluator: evaluatorConfig }),
      post_process_cfg: JSON.stringify(postProcessCfg),
      few_shot_cfg: JSON.stringify({})
    }
  })

  return configs
}